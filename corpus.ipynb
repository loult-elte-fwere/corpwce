{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mboshi/French Corpus : Preliminary analysis\n",
    "\n",
    "## References :\n",
    "\n",
    "+ https://github.com/besacier/mboshi-french-parallel-corpus\n",
    "\n",
    "+ https://github.com/hadware/voxpopuli\n",
    "\n",
    "+ https://www.phon.ucl.ac.uk/home/sampa/\n",
    "\n",
    "## Extracting the french sentences\n",
    "\n",
    "The following snippet can be used to gather all the french sentences of the corpus into a single text file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus generated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "RESSOURCES_DIR = \"/home/kaoro/Documents/vocal_synthesis/mboshi-french-parallel-corpus/full_corpus_newsplit/all/\"\n",
    "\n",
    "paths = os.listdir(RESSOURCES_DIR)\n",
    "\n",
    "with open('french_corpus.txt', 'w') as corpus:\n",
    "    if os.stat(corpus_path).st_size == 0:\n",
    "        for path in paths:\n",
    "            if path.endswith(\".fr\"):\n",
    "                with open(RESSOURCES_DIR + path, 'r') as sentence:\n",
    "                    corpus.write(sentence.read())\n",
    "        print(\"Corpus generated\")\n",
    "    else:\n",
    "        print(\"File already existing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the corpus\n",
    "\n",
    "The generated file, which contains all of the ~5100 french sentences, can then be used to extract some valuable information about phonemes. Those data would be useful to help us determinate to see what kind of process will be needed to make it the corpus more suitable for Mbrola voice creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonetized sentences list generated\n",
      "Corpus size : 80\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('venv/lib/python3.6/site-packages')\n",
    "from voxpopuli import Voice\n",
    "\n",
    "CORPUS_PATH = \"french_corpus.txt\"\n",
    "PHONETIZED_CORPUS_PATH = \"french_corpus_phonemes.txt\"\n",
    "\n",
    "voice = Voice(lang=\"fr\")\n",
    "phonetized_sentences = []\n",
    "phonemes_count = []\n",
    "    \n",
    "with open(CORPUS_PATH, \"r\") as corpus:\n",
    "    content = corpus.readlines()\n",
    "    for x in content:\n",
    "        phonetized_sentences.append(voice.to_phonemes(x.strip()))\n",
    "        \n",
    "print(\"Phonetized sentences list generated\")\n",
    "print(\"Corpus size : {}\".format(len(phonetized_sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract some basics statistics from this corpus, ie average phonemes length and phoneme representation in percent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence lengh in phonemes : 27.3875\n",
      "Representation (in %) for each phonemes in the corpus :\n",
      "\n",
      "a - 201 (9.174%)\n",
      "_ - 198 (9.037%)\n",
      "l - 167 (7.622%)\n",
      "R - 122 (5.568%)\n",
      "i - 109 (4.975%)\n",
      "t - 109 (4.975%)\n",
      "s - 108 (4.929%)\n",
      "E - 106 (4.838%)\n",
      "e - 102 (4.655%)\n",
      "@ - 83 (3.788%)\n",
      "d - 75 (3.423%)\n",
      "m - 75 (3.423%)\n",
      "a~ - 60 (2.738%)\n",
      "k - 57 (2.602%)\n",
      "n - 54 (2.465%)\n",
      "y - 50 (2.282%)\n",
      "o~ - 48 (2.191%)\n",
      "p - 47 (2.145%)\n",
      "z - 44 (2.008%)\n",
      "j - 43 (1.963%)\n",
      "f - 40 (1.826%)\n",
      "u - 39 (1.78%)\n",
      "b - 37 (1.689%)\n",
      "v - 36 (1.643%)\n",
      "O - 36 (1.643%)\n",
      "o - 29 (1.324%)\n",
      "Z - 27 (1.232%)\n",
      "w - 18 (0.822%)\n",
      "S - 17 (0.776%)\n",
      "2 - 14 (0.639%)\n",
      "g - 12 (0.548%)\n",
      "e~ - 12 (0.548%)\n",
      "9 - 9 (0.411%)\n",
      "9~ - 7 (0.319%)\n"
     ]
    }
   ],
   "source": [
    "phonetized_sentences_count = []\n",
    "phonemes_freq = {}\n",
    "\n",
    "for x in phonetized_sentences:\n",
    "    phonetized_sentences_count.append(len(x))\n",
    "\n",
    "print(\"Average sentence lengh in phonemes : {}\".format(sum(phonetized_sentences_count) /\n",
    "                                                       len(phonetized_sentences_count)))\n",
    "\n",
    "for x in phonetized_sentences:\n",
    "    for y in x:\n",
    "        if phonemes_freq.get(y.name):\n",
    "            phonemes_freq[y.name] += 1\n",
    "        else:\n",
    "            phonemes_freq[y.name] = 1\n",
    "\n",
    "        \n",
    "print(\"Representation (in %) for each phonemes in the corpus :\\n\")\n",
    "sorted_freq = sorted(phonemes_freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "for key, value in sorted_freq:\n",
    "    print(\"{} - {} ({}%)\".format(key, value,\n",
    "                                    round(value /\n",
    "                                    sum(phonemes_freq.values()) * 100\n",
    "                                        , 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
