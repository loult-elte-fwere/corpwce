{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mboshi/French Corpus : Preliminary analysis\n",
    "\n",
    "## References :\n",
    "\n",
    "+ https://github.com/besacier/mboshi-french-parallel-corpus\n",
    "\n",
    "+ https://github.com/hadware/voxpopuli\n",
    "\n",
    "+ https://www.phon.ucl.ac.uk/home/sampa/\n",
    "\n",
    "## Extracting the french sentences\n",
    "\n",
    "The following snippet can be used to gather all the french sentences of the corpus into a single text file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus generated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# git clone https://github.com/besacier/mboshi-french-parallel-corpus\n",
    "RESSOURCES_DIR = \"/home/kaoro/Documents/vocal_synthesis/mboshi-french-parallel-corpus/full_corpus_newsplit/all/\"\n",
    "CORPUS_PATH = \"french_corpus.txt\"\n",
    "\n",
    "paths = os.listdir(RESSOURCES_DIR)\n",
    "\n",
    "with open('french_corpus.txt', 'w') as corpus:\n",
    "    if os.stat(CORPUS_PATH).st_size == 0:\n",
    "        for path in paths:\n",
    "            if path.endswith(\".fr\"):\n",
    "                with open(RESSOURCES_DIR + path, 'r') as sentence:\n",
    "                    corpus.write(sentence.read())\n",
    "        print(\"Corpus generated\")\n",
    "    else:\n",
    "        print(\"File already existing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the corpus\n",
    "\n",
    "The generated file, which contains all of the ~5130 french sentences, can then be used to extract some valuable information about phonemes. Those data would be useful to help us determinate to see what kind of process will be needed to make the corpus more suitable for Mbrola voice creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonetized sentences list generated\n",
      "Corpus size : 5130\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('venv/lib/python3.6/site-packages')\n",
    "from voxpopuli import Voice\n",
    "\n",
    "CORPUS_PATH = \"french_corpus.txt\"\n",
    "PHONETIZED_CORPUS_PATH = \"french_corpus_phonemes.txt\"\n",
    "\n",
    "voice = Voice(lang=\"fr\")\n",
    "phonetized_sentences = []\n",
    "phonemes_count = []\n",
    "    \n",
    "with open(CORPUS_PATH, \"r\") as corpus:\n",
    "    content = corpus.readlines()\n",
    "    for x in content:\n",
    "        phonetized_sentences.append(voice.to_phonemes(x.strip()))\n",
    "        \n",
    "print(\"Phonetized sentences list generated\")\n",
    "print(\"Corpus size : {}\".format(len(phonetized_sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average on sentence length and phonemes representation\n",
    "Now we can extract some basics statistics from this corpus, ie average phonemes length and phoneme representation in percent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence lenght in phonemes : 27.151656920077972\n",
      "Representation (in %) for each phonemes in the corpus :\n",
      "\n",
      "_ - 12618 (9.059%)\n",
      "a - 12432 (8.925%)\n",
      "l - 9896 (7.105%)\n",
      "R - 9264 (6.651%)\n",
      "E - 6777 (4.865%)\n",
      "t - 6595 (4.735%)\n",
      "i - 6374 (4.576%)\n",
      "s - 6345 (4.555%)\n",
      "e - 6228 (4.471%)\n",
      "d - 5369 (3.855%)\n",
      "@ - 5261 (3.777%)\n",
      "a~ - 4311 (3.095%)\n",
      "m - 4303 (3.089%)\n",
      "p - 4131 (2.966%)\n",
      "k - 3647 (2.618%)\n",
      "n - 3431 (2.463%)\n",
      "y - 3378 (2.425%)\n",
      "o~ - 2764 (1.984%)\n",
      "b - 2600 (1.867%)\n",
      "v - 2534 (1.819%)\n",
      "u - 2441 (1.752%)\n",
      "O - 2414 (1.733%)\n",
      "f - 2369 (1.701%)\n",
      "j - 2342 (1.681%)\n",
      "z - 2205 (1.583%)\n",
      "Z - 1947 (1.398%)\n",
      "o - 1608 (1.154%)\n",
      "S - 1229 (0.882%)\n",
      "w - 949 (0.681%)\n",
      "e~ - 897 (0.644%)\n",
      "g - 881 (0.633%)\n",
      "9~ - 600 (0.431%)\n",
      "9 - 588 (0.422%)\n",
      "2 - 553 (0.397%)\n",
      "N - 7 (0.005%)\n"
     ]
    }
   ],
   "source": [
    "phonetized_sentences_count = []\n",
    "phonemes_freq = {}\n",
    "\n",
    "for x in phonetized_sentences:\n",
    "    phonetized_sentences_count.append(len(x))\n",
    "\n",
    "print(\"Average sentence lenght in phonemes : {}\".format(sum(phonetized_sentences_count) /\n",
    "                                                       len(phonetized_sentences_count)))\n",
    "\n",
    "for x in phonetized_sentences:\n",
    "    for y in x:\n",
    "        if phonemes_freq.get(y.name):\n",
    "            phonemes_freq[y.name] += 1\n",
    "        else:\n",
    "            phonemes_freq[y.name] = 1\n",
    "\n",
    "        \n",
    "print(\"Representation (in %) for each phonemes in the corpus :\\n\")\n",
    "sorted_freq = sorted(phonemes_freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "for key, value in sorted_freq:\n",
    "    print(\"{} - {} ({}%)\".format(key, value,\n",
    "                                    round(value /\n",
    "                                    sum(phonemes_freq.values()) * 100\n",
    "                                        , 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandi Pandas\n",
    "\n",
    "Let's load the corpus into a serie to leverage the power of Pandas for vizualisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RangeIndex(start=0, stop=5130, step=1)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'PhonemeList'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a1b741e9c12a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average sentence size in phonemes : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max sentence size in phonemes : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Min sentence size in phonemes : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SRC/python/diphones_stats/venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11618\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11619\u001b[0m         return self._reduce(\n\u001b[0;32m> 11620\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11621\u001b[0m         )\n\u001b[1;32m  11622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SRC/python/diphones_stats/venv/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4059\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SRC/python/diphones_stats/venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ALIASES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_NAMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'PhonemeList'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "phonetized_sentences_converted = []\n",
    "\n",
    "for x in phonetized_sentences:\n",
    "    sentence = [y.name for y in x]\n",
    "    phonetized_sentences_converted.append(sentence)\n",
    "\n",
    "sentences = pd.Series(phonetized_sentences_converted)\n",
    "\n",
    "print(sentences.axes)\n",
    "print(\"Average sentence size in phonemes : {}\".format(sentences.mean(axis=x)))\n",
    "print(\"Max sentence size in phonemes : {}\".format(len(sentences.max())))\n",
    "print(\"Min sentence size in phonemes : {}\".format(len(sentences.min())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
